{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing Redis store...\n",
      "Redis store cleared.\n",
      "Index created successfully.\n",
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Clearing existing Qdrant store...\n",
      "Qdrant collection deleted successfully.\n",
      "Qdrant store cleared and collection recreated.\n",
      "Setting up Qdrant collection...\n",
      "Existing Qdrant collection deleted.\n",
      "Qdrant collection created successfully.\n",
      "Running Qdrant Pipeline Test...\n",
      "Processing PDFs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.49s/it]\n"
      "  0%|          | 0/15 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 25.4947 seconds\n",
      "Peak memory usage: 11.19 MiB\n",
      "\n",
      "---Done processing PDFs---\n",
      "\n",
      "Query: What is an AVL Tree?\n",
      "I don't know what an AVL tree is based on the provided context. The context mentions a syllabus for a course, including information about homeworks and practicals, reference materials, and the instructor's name, but it does not provide any definition or explanation of an AVL tree.\n",
      "Time elapsed: 5.753 seconds\n",
      "---------------------------\n",
      "Query: Define the CAP Theorem.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.06 GB, other allocations: 5.27 MB, max allowed: 18.13 GB). Tried to allocate 89.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m LLM_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.2:latest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m EMBEDDING_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQUERIES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLLM_MODEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/College/SP25/DS4300/Practicum/VectorDB-LLM-Project/redis_pipeline.py:326\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(queries, embedding_model, llm_model, chunk_size, overlap)\u001b[0m\n\u001b[1;32m    323\u001b[0m with open(csv_filename, mode=\"a\", newline=\"\") as file:\n\u001b[1;32m    324\u001b[0m     writer = csv.writer(file)\n\u001b[0;32m--> 326\u001b[0m     # Write header only if the file has no data\n\u001b[1;32m    327\u001b[0m     if file.tell() == 0:\n\u001b[1;32m    328\u001b[0m         writer.writerow([\"compute_type\", \"memory_size\", \"embedding_model\", \"llm_model\", \"index_elapsed\", \"index_memory\", \"query\", \"query_time_elapsed\"])\n",
      "File \u001b[0;32m~/College/SP25/DS4300/Practicum/VectorDB-LLM-Project/redis_pipeline.py:227\u001b[0m, in \u001b[0;36msearch_embeddings\u001b[0;34m(query, model, top_k)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# returns time and peak memory\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mround\u001b[39m(elapsed, \u001b[38;5;241m4\u001b[39m), \u001b[38;5;28mround\u001b[39m((peak \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_embeddings\u001b[39m(query, model, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    229\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m get_embedding(query, model)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# Convert embedding to bytes for Redis search\u001b[39;00m\n",
      "File \u001b[0;32m~/College/SP25/DS4300/Practicum/VectorDB-LLM-Project/redis_pipeline.py:93\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, embedding_model)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, embedding_model) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Generate an embedding via a specified model. \u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(text)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:347\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 903 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.06 GB, other allocations: 5.27 MB, max allowed: 18.13 GB). Tried to allocate 89.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Format error in JSON body: value -1817571547831248446 is not a valid point ID, valid values are either an unsigned integer or a UUID\"},\"time\":0.0}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m LLM_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.2:latest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m EMBEDDING_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m run_test(QUERIES, EMBEDDING_MODEL, LLM_MODEL)\n",
      "File \u001b[0;32m~/VectorDB-LLM-Project/qdrant_pipeline.py:241\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(queries, embedding_model, llm_model, chunk_size, overlap)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Qdrant Pipeline Test...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing PDFs...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 241\u001b[0m process_pdfs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlides/\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_model, chunk_size, overlap)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---Done processing PDFs---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n",
      "File \u001b[0;32m~/VectorDB-LLM-Project/qdrant_pipeline.py:100\u001b[0m, in \u001b[0;36mprocess_pdfs\u001b[0;34m(data_dir, model, chunk_size, overlap)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m chunk_index, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[1;32m     99\u001b[0m                 embedding \u001b[38;5;241m=\u001b[39m get_embedding(chunk, model)\n\u001b[0;32m--> 100\u001b[0m                 store_embedding(\n\u001b[1;32m    101\u001b[0m                     file\u001b[38;5;241m=\u001b[39mfile_name,\n\u001b[1;32m    102\u001b[0m                     page\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(page_num),\n\u001b[1;32m    103\u001b[0m                     chunk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(chunk),\n\u001b[1;32m    104\u001b[0m                     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m    105\u001b[0m                 )\n\u001b[1;32m    107\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    108\u001b[0m current, peak \u001b[38;5;241m=\u001b[39m tracemalloc\u001b[38;5;241m.\u001b[39mget_traced_memory()\n",
      "File \u001b[0;32m~/VectorDB-LLM-Project/qdrant_pipeline.py:77\u001b[0m, in \u001b[0;36mstore_embedding\u001b[0;34m(file, page, chunk, embedding)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Store chunk embedding in Qdrant.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_page_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m qdrant_client\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m     78\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mCOLLECTION_NAME,\n\u001b[1;32m     79\u001b[0m     points\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     80\u001b[0m         PointStruct(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mdoc_id, vector\u001b[38;5;241m=\u001b[39membedding, payload\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m: page, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunk})\n\u001b[1;32m     81\u001b[0m     ],\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/qdrant_client.py:1567\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_models(points, is_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m   1568\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   1569\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m   1570\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m   1571\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m   1572\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1574\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/qdrant_remote.py:1908\u001b[0m, in \u001b[0;36mQdrantRemote.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models\u001b[38;5;241m.\u001b[39mBatch):\n\u001b[1;32m   1906\u001b[0m     points \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPointsBatch(batch\u001b[38;5;241m=\u001b[39mpoints, shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector)\n\u001b[0;32m-> 1908\u001b[0m http_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenapi_client\u001b[38;5;241m.\u001b[39mpoints_api\u001b[38;5;241m.\u001b[39mupsert_points(\n\u001b[1;32m   1909\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   1910\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m   1911\u001b[0m     point_insert_operations\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m   1912\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m   1913\u001b[0m )\u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert returned None result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:987\u001b[0m, in \u001b[0;36mSyncPointsApi.upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_points\u001b[39m(\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    979\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m     point_insert_operations: m\u001b[38;5;241m.\u001b[39mPointInsertOperations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    983\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse2006:\n\u001b[1;32m    984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_for_upsert_points(\n\u001b[1;32m    988\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m    989\u001b[0m         wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m    990\u001b[0m         ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m    991\u001b[0m         point_insert_operations\u001b[38;5;241m=\u001b[39mpoint_insert_operations,\n\u001b[1;32m    992\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:512\u001b[0m, in \u001b[0;36m_PointsApi._build_for_upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[1;32m    511\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    513\u001b[0m     type_\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mInlineResponse2006,\n\u001b[1;32m    514\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/collections/\u001b[39m\u001b[38;5;132;01m{collection_name}\u001b[39;00m\u001b[38;5;124m/points\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    517\u001b[0m     path_params\u001b[38;5;241m=\u001b[39mpath_params,\n\u001b[1;32m    518\u001b[0m     params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    519\u001b[0m     content\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    520\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api_client.py:89\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, type_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api_client.py:112\u001b[0m, in \u001b[0;36mApiClient.send\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse\u001b[38;5;241m.\u001b[39mfor_response(response)\n",
      "\u001b[0;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Format error in JSON body: value -1817571547831248446 is not a valid point ID, valid values are either an unsigned integer or a UUID\"},\"time\":0.0}'"
     ]
    }
   ],
   "source": [
    "from qdrant_pipeline import run_test\n",
    "\n",
    "QUERIES = [\n",
    "    'What is an AVL Tree?',\n",
    "    'Define the CAP Theorem.',\n",
    "    'How can I connect to a Mongo Database through Python?',\n",
    "    'Why are the pros of cons of using a linked list versus using an array?',\n",
    "    'Give me pseudocode for a Binary Search Tree Node.'\n",
    "]\n",
    "\n",
    "LLM_MODEL = 'llama3.2:latest'\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "run_test(QUERIES, EMBEDDING_MODEL, LLM_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
